{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Neural Networks Demystified [Part 1]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommended [Jupyter Theme](https://github.com/dunovank/jupyter-themes) for presenting this notebook:\n",
    "````\n",
    "jt -t grade3 -cellw=90% -fs=20 -tfs=20 -ofs=20\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here's we'll get a little deeper into the [Neural Networks Demystified](https://www.youtube.com/watch?v=bxe2T-V8XRs) series.\n",
    "- My hoped for outcome for you here is that you walk away with a fundamental understanding of the basic functioning of neural networks. There's lots of bells and whistles that we'll add later, but this module is just about **the basics**. \n",
    "- Really grasping the basics will serve you well when things start to get complex in the **deep learning** module.\n",
    "- To keep our focuse on the network itself, we'll use really really simple toy data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/nnd1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's get our data into numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = (hours sleeping, hours studying), y = Score on test\n",
    "X = np.array(([3,5], [5,1], [10,2]), dtype=float)\n",
    "y = np.array(([75], [82], [93]), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  5.],\n",
       "       [ 5.,  1.],\n",
       "       [10.,  2.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75.],\n",
       "       [82.],\n",
       "       [93.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we doing again?\n",
    "Now, the big idea here, of course, is that we're going to use a neural network to predict your scores on a test based on how many hours you sleep and how many hours you study the night before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/nnd2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a **supervised regression** problem. \n",
    "- What is the difference between supervised and unsupervised machine learning?\n",
    "- What is the difference between regression and classification problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/nnd3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before we get going, we need to scale our input data\n",
    "- It's crazy how easy it is to forget to do this, and how **big** of a difference it can make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X/np.amax(X, axis=0)\n",
    "y = y/100 #Max test score is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3, 1. ],\n",
       "       [0.5, 0.2],\n",
       "       [1. , 0.4]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75],\n",
       "       [0.82],\n",
       "       [0.93]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/nnd4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synapses\n",
    "- Synapses have a reall simple job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../videos/nn_basics.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/nnd5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nuerons are responsible for adding up all their inputs and applying an activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](../graphics/NNQ8-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Setup out Network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I recommend watching [Nueral Networks Demystified Parts 1 - 4](https://www.youtube.com/watch?v=UJwK6jAStmg) before this section. \n",
    "- We'll skip the details here, and fill back in if we have time. However the main focus of this lecture is backprop!\n",
    "- Here's our archicture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/nnd6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our key variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Code Symbol | Math Symbol | Definition | Dimensions\n",
    "| :-: | :-: | :-: | :-: |\n",
    "|X|$$X$$|Input Data, each row in an example| (numExamples, inputLayerSize)|\n",
    "|y |$$y$$|target data|(numExamples, outputLayerSize)|\n",
    "|W1 | $$W^{(1)}$$ | Layer 1 weights | (inputLayerSize, hiddenLayerSize) |\n",
    "|W2 | $$W^{(2)}$$ | Layer 2 weights | (hiddenLayerSize, outputLayerSize) |\n",
    "|z2 | $$z^{(2)}$$ | Layer 2 activation | (numExamples, hiddenLayerSize) |\n",
    "|a2 | $$a^{(2)}$$ | Layer 2 activity | (numExamples, hiddenLayerSize) |\n",
    "|z3 | $$z^{(3)}$$ | Layer 3 activation | (numExamples, outputLayerSize) |\n",
    "|J | $$J$$ | Cost | (1, outputLayerSize) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our \"forward\" equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$\n",
    "z^{(2)} = XW^{(1)} \\tag{1}\\\\\n",
    "$$\n",
    "\n",
    "## $$\n",
    "a^{(2)} = f(z^{(2)}) \\tag{2}\\\\\n",
    "$$\n",
    "\n",
    "## $$\n",
    "z^{(3)} = a^{(2)}W^{(2)} \\tag{3}\\\\\n",
    "$$\n",
    "\n",
    "## $$\n",
    "\\hat{y} = f(z^{(3)}) \\tag{4}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And our python implementation of \"forward\" propogation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):        \n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        #Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize, self.outputLayerSize)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #Propagate inputs though network\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        yHat = self.sigmoid(self.z3) \n",
    "        return yHat\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try out our network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN = Neural_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yHat = NN.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72460972],\n",
       "       [0.45726262],\n",
       "       [0.48234454]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yHat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75],\n",
       "       [0.82],\n",
       "       [0.93]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x105fc4198>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAFpCAYAAABeYWb6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrd/lggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105f6d080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Compare estimate, yHat, to actually score\n",
    "fig = figure(0, (10, 6))\n",
    "bar([0,1,2], yHat.ravel(), width = 0.35, color='b', alpha=0.8)\n",
    "bar([0.35,1.35,2.35], y.ravel(), width = 0.35, color = 'g', alpha=0.8)\n",
    "\n",
    "grid(1)\n",
    "legend(['$\\hat{y}$', '$y$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why are our predictions so bad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## So, how do we make better predictions?\n",
    "- A good place to start is by measuing just how bad our performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../videos/error_calculation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$\n",
    "J = \\sum \\frac{1}{2}(y-\\hat{y})^2 \\tag{5}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- J is our cost! To train our network we must **minimize our cost function**.\n",
    "- What is the dimensionality of our cost?\n",
    "- Now that we've defined our cost mathematically, let's code it up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75],\n",
       "       [0.82],\n",
       "       [0.93]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72460972],\n",
       "       [0.45726262],\n",
       "       [0.48234454]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yHat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "J = 0.5*sum((y-yHat)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16630924160794136"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Our whole job now is to find some values of $W^{(1)}$ and $W^{(2)}$ that minimize J!\n",
    "- How many numbers is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.67100692, -0.69971486, -1.49377772],\n",
       "       [-0.28767178, -1.06171566,  2.15447908]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.5570039 ],\n",
       "       [-0.42195794],\n",
       "       [ 2.40068876]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.W2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Just 9 numbers, how hard could this be!?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../videos/brute_force.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why can't we just try all the Ws?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a really important concept, we'll discuss in class quickly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Since we can't just \"try all the weights\", we're going to have to be *more clever*. \n",
    "- One interesting idea is to constrain our search be computing which direction is \"downhill\" in the 9 dimensional space of our cost function input. \n",
    "- This idea is called **Gradient Descent**, and it's cool AF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](../graphics/nnd7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- This is kinda fun to think about in high dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../videos/grad_descent.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When might this fail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/nnd8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient descent fails if our loss function is non-convex\n",
    "- Somehow, this is much less of problem than reserachers originally thought. \n",
    "- Check out [Yann Lecun's Fun Talk](https://www.youtube.com/watch?v=8zdo6cnCW2w) on this for more info.\n",
    "- So ignoring that pesky convexity issue, if we're going to follow our gradient downwill, first we need to estimate or compute it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is our job for the rest of today. Given our equations thusfar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$\n",
    "z^{(2)} = XW^{(1)} \\tag{1}\\\\\n",
    "$$\n",
    "## $$\n",
    "a^{(2)} = f(z^{(2)}) \\tag{2}\\\\\n",
    "$$\n",
    "## $$\n",
    "z^{(3)} = a^{(2)}W^{(2)} \\tag{3}\\\\\n",
    "$$\n",
    "## $$\n",
    "\\hat{y} = f(z^{(3)}) \\tag{4}\\\\\n",
    "$$\n",
    "## $$\n",
    "J = \\sum \\frac{1}{2}(y-\\hat{y})^2 \\tag{5}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to estimate our gradients:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$ \n",
    "\\frac{\\partial J}{\\partial W^{(1)}} = ? \n",
    "\\frac{\\partial J}{\\partial W^{(2)}} = ? \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try something a little different and workout the details using some guided notes. These will be on github, be sure to print before the lecture!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
